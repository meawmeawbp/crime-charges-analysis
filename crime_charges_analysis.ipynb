{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31f088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\miewmiew\\Hackathon\\Hack2\\.venv\\Scripts\\python.exe\n",
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sys, sklearn\n",
    "print(sys.executable)\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff889007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เซลล์ 1: Setup\n",
    "import ast\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110feee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd          : c:\\miewmiew\\Hackathon\\Hack2\n",
      "in cwd       : ['.venv', 'crime-charges-analysis', 'crime-charges-analysis.zip', 'crime_charges_analysis.ipynb']\n",
      "parent       : c:\\miewmiew\\Hackathon\n",
      "in parent    : ['.venv', 'compare_top_bottom_stores.ipynb', 'data', 'Hack1', 'Hack2', 'q1competition.ipynb']\n",
      "grand parent : c:\\miewmiew\n",
      "in grandpar : ['Hackathon', 'readfile.py', 'root', 'superai']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. ดู current working directory\n",
    "print(\"cwd          :\", os.getcwd())\n",
    "\n",
    "# 2. ดูไฟล์/โฟลเดอร์ใน cwd\n",
    "print(\"in cwd       :\", os.listdir('.'))\n",
    "\n",
    "# 3. ดูไฟล์/โฟลเดอร์ใน parent directory\n",
    "parent = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(\"parent       :\", parent)\n",
    "print(\"in parent    :\", os.listdir(parent))\n",
    "\n",
    "# 4. ดูอีกขั้นนึง (grand-parent ถ้าจำเป็น)\n",
    "grand = os.path.abspath(os.path.join(parent, os.pardir))\n",
    "print(\"grand parent :\", grand)\n",
    "print(\"in grandpar :\", os.listdir(grand))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5b3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: crime-charges-analysis\n",
      "['classes.xlsx', 'dev_half.csv', 'submission.csv', 'train.csv', 'train_half.csv']\n"
     ]
    }
   ],
   "source": [
    "# เซลล์ เช็กและแตก ZIP ก่อน โหลดข้อมูล\n",
    "import os, zipfile\n",
    "\n",
    "# ชื่อไฟล์ ZIP ที่อยู่ใน cwd\n",
    "zip_path = \"crime-charges-analysis.zip\"\n",
    "# ชื่อโฟลเดอร์ที่จะเก็บข้อมูลหลังแตก\n",
    "extract_dir = \"crime-charges-analysis\"\n",
    "\n",
    "# ถ้ายังไม่มีโฟลเดอร์ให้แตก ZIP\n",
    "if not os.path.isdir(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(extract_dir)\n",
    "    print(\"Extracted to:\", extract_dir)\n",
    "else:\n",
    "    print(\"Directory already exists:\", extract_dir)\n",
    "\n",
    "# ตรวจดูไฟล์ภายในโฟลเดอร์\n",
    "print(os.listdir(extract_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a985010",
   "metadata": {},
   "source": [
    "Ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dcbde",
   "metadata": {},
   "source": [
    "ประมาณไม่เกิน1นาที 35-40วินาที"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a721c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [65 lines of output]\n",
      "      Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-80.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "      Collecting cython<3.0,>=0.25\n",
      "        Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "      Collecting cymem<2.1.0,>=2.0.2\n",
      "        Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "      Collecting preshed<3.1.0,>=3.0.2\n",
      "        Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting murmurhash<1.1.0,>=0.28.0\n",
      "        Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "      Collecting thinc<8.4.0,>=8.3.0\n",
      "        Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "      Collecting numpy<2.1.0,>=2.0.0\n",
      "        Using cached numpy-2.0.2.tar.gz (18.9 MB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Installing backend dependencies: started\n",
      "        Installing backend dependencies: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        ร— Preparing metadata (pyproject.toml) did not run successfully.\n",
      "        โ”\\x82 exit code: 1\n",
      "        โ•ฐโ”€> [21 lines of output]\n",
      "            + C:\\miewmiew\\Hackathon\\Hack2\\.venv\\Scripts\\python.exe C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\\vendored-meson\\meson\\meson.py setup C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\\.mesonpy-pq6_lc0a -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\\.mesonpy-pq6_lc0a\\meson-python-native-file.ini\n",
      "            The Meson build system\n",
      "            Version: 1.4.99\n",
      "            Source dir: C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\n",
      "            Build dir: C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\\.mesonpy-pq6_lc0a\n",
      "            Build type: native build\n",
      "            Project name: NumPy\n",
      "            Project version: 2.0.2\n",
      "            WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "      \n",
      "            ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "            The following exception(s) were encountered:\n",
      "            Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "            Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "            A full log can be found at C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-install-nopwpox2\\numpy_553329fe8d8f42ac86445011d4bb269a\\.mesonpy-pq6_lc0a\\meson-logs\\meson-log.txt\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      ร— Encountered error while generating package metadata.\n",
      "      โ•ฐโ”€> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "c:\\miewmiew\\Hackathon\\Hack2\\.venv\\Scripts\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "# ติดตั้ง spaCy\n",
    "!pip install spacy\n",
    "\n",
    "# ดาวน์โหลดโมเดลภาษาไทย\n",
    "!python -m spacy download th_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489c50b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythainlp in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: torch in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from pythainlp) (2.32.3)\n",
      "Requirement already satisfied: tzdata in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from pythainlp) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from torch) (80.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from requests>=2.31->pythainlp) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from requests>=2.31->pythainlp) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from requests>=2.31->pythainlp) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from requests>=2.31->pythainlp) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\miewmiew\\hackathon\\hack2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 1) ติดตั้ง (ถ้ายังไม่ติดตั้ง)\n",
    "!pip install pythainlp torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a78c8",
   "metadata": {},
   "source": [
    "ไม่ทำnerละ ทำไม่ได้"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be586af5",
   "metadata": {},
   "source": [
    "ML baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce471f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (macro): 0.6605556701269235\n",
      "\n",
      "Detailed report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.56      0.51       307\n",
      "           2       0.65      0.79      0.71       417\n",
      "           3       0.63      0.71      0.66       190\n",
      "           4       0.66      0.83      0.74       255\n",
      "           5       0.55      0.75      0.63       373\n",
      "           6       0.64      0.69      0.66       251\n",
      "           7       0.59      0.89      0.71       247\n",
      "\n",
      "   micro avg       0.59      0.75      0.66      2040\n",
      "   macro avg       0.60      0.75      0.66      2040\n",
      "weighted avg       0.59      0.75      0.66      2040\n",
      " samples avg       0.57      0.72      0.61      2040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miewmiew\\Hackathon\\Hack2\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# === เตรียม Data ===\n",
    "import pandas as pd, ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# โหลด data ที่แบ่งไว้\n",
    "train_df = pd.read_csv(\"crime-charges-analysis/train_half.csv\")\n",
    "dev_df   = pd.read_csv(\"crime-charges-analysis/dev_half.csv\")\n",
    "\n",
    "# ฟังก์ชัน parse answers\n",
    "def parse_answers(cell):\n",
    "    lst = ast.literal_eval(cell)\n",
    "    out = {}\n",
    "    for d in lst:\n",
    "        for p, cs in d.items():\n",
    "            out[p] = ast.literal_eval(cs)\n",
    "    return out\n",
    "\n",
    "train_df[\"parsed\"] = train_df[\"answers\"].apply(parse_answers)\n",
    "dev_df  [\"parsed\"] = dev_df  [\"answers\"].apply(parse_answers)\n",
    "\n",
    "# สร้าง X, y สำหรับแต่ละ (person, story)\n",
    "X_train, y_train = [], []\n",
    "for _, row in train_df.iterrows():\n",
    "    story = row[\"story\"]\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_train.append(f\"{person} [SEP] {story}\")\n",
    "        y_train.append(charges)\n",
    "\n",
    "X_dev, y_dev = [], []\n",
    "for _, row in dev_df.iterrows():\n",
    "    story = row[\"story\"]\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_dev.append(f\"{person} [SEP] {story}\")\n",
    "        y_dev.append(charges)\n",
    "\n",
    "# แปลง labels → binary matrix\n",
    "mlb = MultiLabelBinarizer(classes=[1,2,3,4,5,6,7])\n",
    "Y_train = mlb.fit_transform(y_train)\n",
    "Y_dev   = mlb.transform(y_dev)\n",
    "\n",
    "# === สร้าง & เทรน Pipeline ===\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=30000)),\n",
    "    (\"clf\", OneVsRestClassifier(\n",
    "        LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\"), \n",
    "        n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# === ประเมินผลบน Dev ===\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "Y_pred = pipeline.predict(X_dev)\n",
    "print(\"F1-score (macro):\", f1_score(Y_dev, Y_pred, average=\"macro\"))\n",
    "print(\"\\nDetailed report:\\n\", classification_report(Y_dev, Y_pred, target_names=[str(i) for i in mlb.classes_]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456300a0",
   "metadata": {},
   "source": [
    "เริ่มรันการวิเคราะห์ข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d70971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train half: (900, 3)\n",
      "Dev   half: (900, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"crime-charges-analysis/train_half.csv\")\n",
    "dev_df   = pd.read_csv(\"crime-charges-analysis/dev_half.csv\")\n",
    "\n",
    "print(\"Train half:\", train_df.shape)\n",
    "print(\"Dev   half:\", dev_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6786a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answers</th>\n",
       "      <th>answers_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6AzyVcLTK0</td>\n",
       "      <td>[{'งิ่มเฮียง': '[2,5,7]'}]</td>\n",
       "      <td>{'งิ่มเฮียง': [2, 5, 7]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KVG7hHQ1L8</td>\n",
       "      <td>[{'เจตน์ณัชนัย': '[1]'}, {'คออีก': '[5,7]'}]</td>\n",
       "      <td>{'เจตน์ณัชนัย': [1], 'คออีก': [5, 7]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7YGDGTUHqt</td>\n",
       "      <td>[{'กำไล': '[1]'}, {'กัมปณันท์': '[2,4]'}, {'ขว...</td>\n",
       "      <td>{'กำไล': [1], 'กัมปณันท์': [2, 4], 'ขวัญชีวี':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            answers  \\\n",
       "0  6AzyVcLTK0                         [{'งิ่มเฮียง': '[2,5,7]'}]   \n",
       "1  KVG7hHQ1L8       [{'เจตน์ณัชนัย': '[1]'}, {'คออีก': '[5,7]'}]   \n",
       "2  7YGDGTUHqt  [{'กำไล': '[1]'}, {'กัมปณันท์': '[2,4]'}, {'ขว...   \n",
       "\n",
       "                                      answers_parsed  \n",
       "0                           {'งิ่มเฮียง': [2, 5, 7]}  \n",
       "1              {'เจตน์ณัชนัย': [1], 'คออีก': [5, 7]}  \n",
       "2  {'กำไล': [1], 'กัมปณันท์': [2, 4], 'ขวัญชีวี':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def parse_answers(cell: str) -> dict[str, list[int]]:\n",
    "    raw = ast.literal_eval(cell)  # list of dicts\n",
    "    out = {}\n",
    "    for d in raw:\n",
    "        for person, charges_str in d.items():\n",
    "            out[person] = ast.literal_eval(charges_str)\n",
    "    return out\n",
    "\n",
    "# สร้างคอลัมน์ใหม่\n",
    "train_df[\"answers_parsed\"] = train_df[\"answers\"].apply(parse_answers)\n",
    "dev_df[\"answers_parsed\"]   = dev_df[\"answers\"].apply(parse_answers)\n",
    "\n",
    "# ตรวจสอบ\n",
    "display(train_df[[\"id\",\"answers\",\"answers_parsed\"]].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92f798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train long: (2087, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>story</th>\n",
       "      <th>person</th>\n",
       "      <th>charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6AzyVcLTK0</td>\n",
       "      <td>งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน</td>\n",
       "      <td>งิ่มเฮียง</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6AzyVcLTK0</td>\n",
       "      <td>งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน</td>\n",
       "      <td>งิ่มเฮียง</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6AzyVcLTK0</td>\n",
       "      <td>งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน</td>\n",
       "      <td>งิ่มเฮียง</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KVG7hHQ1L8</td>\n",
       "      <td>คออีกวางแผนใส่สารหนูในขนมปังที่เจตน์ณัชนัยชอบก...</td>\n",
       "      <td>เจตน์ณัชนัย</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KVG7hHQ1L8</td>\n",
       "      <td>คออีกวางแผนใส่สารหนูในขนมปังที่เจตน์ณัชนัยชอบก...</td>\n",
       "      <td>คออีก</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              story       person  \\\n",
       "0  6AzyVcLTK0  งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน    งิ่มเฮียง   \n",
       "1  6AzyVcLTK0  งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน    งิ่มเฮียง   \n",
       "2  6AzyVcLTK0  งิ่มเฮียงขโมยกระเป๋าจากตลาดแล้วยิงฆ่าลูกค้าในร้าน    งิ่มเฮียง   \n",
       "3  KVG7hHQ1L8  คออีกวางแผนใส่สารหนูในขนมปังที่เจตน์ณัชนัยชอบก...  เจตน์ณัชนัย   \n",
       "4  KVG7hHQ1L8  คออีกวางแผนใส่สารหนูในขนมปังที่เจตน์ณัชนัยชอบก...        คออีก   \n",
       "\n",
       "   charge  \n",
       "0       2  \n",
       "1       5  \n",
       "2       7  \n",
       "3       1  \n",
       "4       5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for _, row in train_df.iterrows():\n",
    "    sid = row[\"id\"]\n",
    "    text = row[\"story\"]\n",
    "    for person, charges in row[\"answers_parsed\"].items():\n",
    "        for c in charges:\n",
    "            rows.append({\"id\": sid, \"story\": text, \"person\": person, \"charge\": c})\n",
    "\n",
    "train_long = pd.DataFrame(rows)\n",
    "print(\"Train long:\", train_long.shape)\n",
    "display(train_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82128e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ไม่มีความผิดหรือไม่มีความเกี่ยวข้องกับเหตุการณ์</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ลักทรัพย์หรือชิงทรัพย์</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>กระทำการใดๆด้วยความประมาทหรือละเลยส่งผลให้เกิด...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>บุกรุกเข้าเขตหวงห้ามหรือนอกเวลาทำการ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>กระทำการใดๆด้วยเจตนาที่ส่งผลให้เกิดความเสียหาย...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ฉ้อโกงประชาชน, ปลอมแปลงเอกสาร หรือปลอมแปลงสิ่ง...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ทำให้มีคนตายด้วยวิธีการใดๆก็ตาม</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                        Description\n",
       "0      1    ไม่มีความผิดหรือไม่มีความเกี่ยวข้องกับเหตุการณ์\n",
       "1      2                             ลักทรัพย์หรือชิงทรัพย์\n",
       "2      3  กระทำการใดๆด้วยความประมาทหรือละเลยส่งผลให้เกิด...\n",
       "3      4               บุกรุกเข้าเขตหวงห้ามหรือนอกเวลาทำการ\n",
       "4      5  กระทำการใดๆด้วยเจตนาที่ส่งผลให้เกิดความเสียหาย...\n",
       "5      6  ฉ้อโกงประชาชน, ปลอมแปลงเอกสาร หรือปลอมแปลงสิ่ง...\n",
       "6      7                    ทำให้มีคนตายด้วยวิธีการใดๆก็ตาม"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.read_excel(\"crime-charges-analysis/classes.xlsx\")\n",
    "display(classes)\n",
    "\n",
    "# สร้าง dict id→list of keywords (เบื้องต้น)\n",
    "crime_keywords = {\n",
    "    2: [\"ขโมย\",\"ลัก\",\"ชิงทรัพย์\"],\n",
    "    3: [\"ประมาท\",\"ไม่ตั้งใจ\"],\n",
    "    4: [\"บุกรุก\"],\n",
    "    5: [\"เจตนา\",\"จงใจ\",\"ทำร้าย\"],\n",
    "    6: [\"ฉ้อโกง\",\"ปลอมแปลง\"],\n",
    "    7: [\"ฆ่า\",\"ตาย\",\"เสียชีวิต\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677efe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify_text(text: str) -> dict[str, list[int]]:\n",
    "    # ดึงรายชื่อจาก train set\n",
    "    names = train_df[\"answers_parsed\"].explode().index  # หรือสร้าง gazetteer list\n",
    "    # เตรียม dict เปล่า\n",
    "    pred = {p: [] for p in train_df[\"answers_parsed\"].iloc[0].keys()}\n",
    "    \n",
    "    for sent in re.split(r\"[\\.!?]\", text):\n",
    "        sl = sent.lower()\n",
    "        detected = {cls for cls, kws in crime_keywords.items() if any(kw in sl for kw in kws)}\n",
    "        if 7 in detected:\n",
    "            if 5 in detected: detected.add(5)\n",
    "            elif 3 in detected: detected.add(3)\n",
    "        for name in pred:\n",
    "            if name in sent:\n",
    "                pred[name].extend(detected)\n",
    "    # จัด final\n",
    "    for name, lst in pred.items():\n",
    "        uniq = sorted(set(lst))\n",
    "        pred[name] = uniq or [1]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6917404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 (macro): 0.44154057771664373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for _, row in dev_df.iterrows():\n",
    "    gt = row[\"answers_parsed\"]                # dict person→charges list\n",
    "    pred = classify_text(row[\"story\"])        # dict same format\n",
    "    for person, charges in gt.items():\n",
    "        for c in range(1,8):\n",
    "            y_true.append(int(c in charges))\n",
    "            y_pred.append(int(c in pred.get(person,[])))\n",
    "\n",
    "print(\"Dev F1 (macro):\", f1_score(y_true, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22b9c2",
   "metadata": {},
   "source": [
    "บันทึกไฟล์ summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"crime-charges-analysis/submission.csv\")\n",
    "subs = []\n",
    "for _, row in train_df.iterrows():  # แทน test.csv จริงใช้ dev_df หรือโหลด test.csv มาใช้นะ\n",
    "    lst = [{p: str(ch)} for p,ch in classify_text(row[\"story\"]).items()]\n",
    "    subs.append(lst)\n",
    "sample[\"answers\"] = subs\n",
    "sample.to_csv(\"my_submission.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87c202",
   "metadata": {},
   "source": [
    "เพิ่มคะแนน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb87e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.56      0.51       307\n",
      "           2       0.65      0.79      0.71       417\n",
      "           3       0.63      0.71      0.66       190\n",
      "           4       0.66      0.83      0.74       255\n",
      "           5       0.55      0.75      0.63       373\n",
      "           6       0.64      0.69      0.66       251\n",
      "           7       0.59      0.89      0.71       247\n",
      "\n",
      "   micro avg       0.59      0.75      0.66      2040\n",
      "   macro avg       0.60      0.75      0.66      2040\n",
      "weighted avg       0.59      0.75      0.66      2040\n",
      " samples avg       0.57      0.72      0.61      2040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miewmiew\\Hackathon\\Hack2\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    Y_dev, Y_pred,\n",
    "    target_names=[str(i) for i in mlb.classes_]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18cd06aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: thresh=0.40, F1=0.524\n",
      "Class 2: thresh=0.50, F1=0.712\n",
      "Class 3: thresh=0.45, F1=0.676\n",
      "Class 4: thresh=0.55, F1=0.739\n",
      "Class 5: thresh=0.50, F1=0.635\n",
      "Class 6: thresh=0.45, F1=0.677\n",
      "Class 7: thresh=0.50, F1=0.706\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "probs = pipeline.predict_proba(X_dev)  # shape (n_samples, n_classes)\n",
    "best_thresh = {}\n",
    "for i, cls in enumerate(mlb.classes_):\n",
    "    best_f1, best_t = 0, 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 17):\n",
    "        y_pred_t = (probs[:, i] >= t).astype(int)\n",
    "        f1 = f1_score(Y_dev[:, i], y_pred_t)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    best_thresh[cls] = best_t\n",
    "    print(f\"Class {cls}: thresh={best_t:.2f}, F1={best_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31965885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 with tuned thresholds: 0.6670658474105817\n"
     ]
    }
   ],
   "source": [
    "Y_pred_thr = np.zeros_like(probs, dtype=int)\n",
    "for i, cls in enumerate(mlb.classes_):\n",
    "    Y_pred_thr[:, i] = (probs[:, i] >= best_thresh[cls]).astype(int)\n",
    "\n",
    "print(\"F1 with tuned thresholds:\", \n",
    "      f1_score(Y_dev, Y_pred_thr, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "929a3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With lex features: 0.5179174402411891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "class KeywordFlag(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, keywords): self.keywords = keywords\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        # X is list of strings \"person [SEP] story\"\n",
    "        flags = []\n",
    "        for text in X:\n",
    "            story = text.split(\"[SEP]\")[1]\n",
    "            lower = story.lower()\n",
    "            flags.append([1 if kw in lower else 0 for kw in self.keywords])\n",
    "        return np.array(flags)\n",
    "\n",
    "# สมมติเรา flatten keywords ทั้งหมดลง list เดียว\n",
    "all_keywords = sum(crime_keywords.values(), [])\n",
    "lex_union = FeatureUnion([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=20000)),\n",
    "    (\"lex\", KeywordFlag(all_keywords))\n",
    "])\n",
    "\n",
    "hybrid = Pipeline([\n",
    "    (\"features\", lex_union),\n",
    "    (\"clf\", OneVsRestClassifier(LogisticRegression(solver=\"liblinear\"), n_jobs=-1))\n",
    "])\n",
    "hybrid.fit(X_train, Y_train)\n",
    "Yh_pred = hybrid.predict(X_dev)\n",
    "print(\"With lex features:\", f1_score(Y_dev, Yh_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f1841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_hybrid(text):\n",
    "    rule = classify_text(text)        # dict person→[classes]\n",
    "    Xs   = [f\"{p} [SEP] {text}\" for p in rule]\n",
    "    probs = pipeline.predict_proba(Xs)  # หรือ hybrid.predict_proba\n",
    "    out = {}\n",
    "    for idx, p in enumerate(rule):\n",
    "        ml_preds = [cls for cls, prob in zip(mlb.classes_, probs[idx]) \n",
    "                    if prob >= best_thresh[cls]]\n",
    "        combo = sorted(set(rule[p]) | set(ml_preds)) or [1]\n",
    "        out[p] = combo\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52497ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid F1: 0.5016968581991004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_hybrid_true, y_hybrid_pred = [], []\n",
    "\n",
    "for _, row in dev_df.iterrows():\n",
    "    # parse ground-truth\n",
    "    gt = parse_answers(row[\"answers\"])        # dict: person → [charges]\n",
    "    # hybrid prediction\n",
    "    pred = classify_hybrid(row[\"story\"])      # dict: person → [charges]\n",
    "    \n",
    "    for person, true_charges in gt.items():\n",
    "        # if hybrid didn’t predict this person at all, assume [1]\n",
    "        pred_charges = pred.get(person, [1])\n",
    "        \n",
    "        for cls in mlb.classes_:             # classes = [1,2,…,7]\n",
    "            y_hybrid_true.append(int(cls in true_charges))\n",
    "            y_hybrid_pred.append(int(cls in pred_charges))\n",
    "\n",
    "# now compute your F1\n",
    "print(\"Hybrid F1:\", f1_score(y_hybrid_true, y_hybrid_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3631fdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m y_hybrid_true, y_hybrid_pred = [], []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdev_df\u001b[49m.iterrows():\n\u001b[32m      3\u001b[39m     gt = parse_answers(row[\u001b[33m\"\u001b[39m\u001b[33manswers\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m     pred = classify_hybrid(row[\u001b[33m\"\u001b[39m\u001b[33mstory\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'dev_df' is not defined"
     ]
    }
   ],
   "source": [
    "y_hybrid_true, y_hybrid_pred = [], []\n",
    "for _, row in dev_df.iterrows():\n",
    "    gt = parse_answers(row[\"answers\"])\n",
    "    pred = classify_hybrid(row[\"story\"])\n",
    "    for person in gt:\n",
    "        for cls in mlb.classes_:\n",
    "            y_hybrid_true.append(int(cls in gt[person]))\n",
    "            y_hybrid_pred.append(int(cls in pred[person]))\n",
    "print(\"Hybrid F1:\", f1_score(y_hybrid_true, y_hybrid_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5606e",
   "metadata": {},
   "source": [
    "โค้ดเดียวจบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488b83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid F1 (macro): 0.5016968581991004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# กำหนด list ของคลาสตั้งแต่ 1–7\n",
    "classes_list = [1,2,3,4,5,6,7]\n",
    "\n",
    "y_hybrid_true, y_hybrid_pred = [], []\n",
    "\n",
    "for _, row in dev_df.iterrows():\n",
    "    gt = parse_answers(row[\"answers\"])         # dict จริง\n",
    "    pred = classify_hybrid(row[\"story\"])       # dict ทำนาย\n",
    "\n",
    "    for person, true_charges in gt.items():\n",
    "        # ถ้า hybrid ไม่ทำนายชื่อนี้ ให้ถือว่าคลาส [1]\n",
    "        pred_charges = pred.get(person, [1])\n",
    "        for cls in classes_list:\n",
    "            y_hybrid_true.append( 1 if cls in true_charges else 0 )\n",
    "            y_hybrid_pred.append( 1 if cls in pred_charges else 0 )\n",
    "\n",
    "print(\"Hybrid F1 (macro):\", f1_score(y_hybrid_true, y_hybrid_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83750895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid F1 (macro): 0.5016968581991004\n"
     ]
    }
   ],
   "source": [
    "# 1) โหลดและ parse dev set\n",
    "import pandas as pd, ast\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dev_df = pd.read_csv(\"crime-charges-analysis/dev_half.csv\")\n",
    "\n",
    "def parse_answers(cell: str) -> dict[str, list[int]]:\n",
    "    raw = ast.literal_eval(cell)\n",
    "    out = {}\n",
    "    for d in raw:\n",
    "        for person, charges_str in d.items():\n",
    "            out[person] = ast.literal_eval(charges_str)\n",
    "    return out\n",
    "\n",
    "dev_df[\"parsed\"] = dev_df[\"answers\"].apply(parse_answers)\n",
    "\n",
    "# 2) ใส่ฟังก์ชัน classify_hybrid ของคุณตรงนี้\n",
    "def classify_hybrid(text: str) -> dict[str, list[int]]:\n",
    "    # TODO: เปลี่ยนเป็น logic Ensemble ที่คุณพัฒนาจริง\n",
    "    # ตัวอย่าง dummy: ทุกคนไม่มีข้อหา ([1])\n",
    "    # ให้กลับเป็น dict person → [1]\n",
    "    # แต่ถ้าคุณมี rule-based/ML ผสม ให้ใส่ที่นี่เลย\n",
    "    sample_persons = list(dev_df[\"parsed\"].iloc[0].keys())\n",
    "    return {p: [1] for p in sample_persons}\n",
    "\n",
    "# 3) คำนวณ Hybrid F1\n",
    "classes_list = [1,2,3,4,5,6,7]\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for _, row in dev_df.iterrows():\n",
    "    gt   = row[\"parsed\"]                 # dict ของจริง\n",
    "    pred = classify_hybrid(row[\"story\"]) # dict ทำนาย\n",
    "\n",
    "    for person, true_charges in gt.items():\n",
    "        pred_charges = pred.get(person, [1])  # default เป็น [1] ถ้าไม่มี\n",
    "        for cls in classes_list:\n",
    "            y_true.append(1 if cls in true_charges else 0)\n",
    "            y_pred.append(1 if cls in pred_charges else 0)\n",
    "\n",
    "print(\"Hybrid F1 (macro):\", f1_score(y_true, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb9dde",
   "metadata": {},
   "source": [
    "เพิ่มคะแนน2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc1c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: best threshold = 0.40 with F1 = 0.524\n",
      "Class 2: best threshold = 0.50 with F1 = 0.712\n",
      "Class 3: best threshold = 0.45 with F1 = 0.676\n",
      "Class 4: best threshold = 0.55 with F1 = 0.739\n",
      "Class 5: best threshold = 0.50 with F1 = 0.635\n",
      "Class 6: best threshold = 0.45 with F1 = 0.677\n",
      "Class 7: best threshold = 0.50 with F1 = 0.706\n",
      "\n",
      "Threshold dictionary: {1: np.float64(0.4), 2: np.float64(0.5), 3: np.float64(0.45000000000000007), 4: np.float64(0.55), 5: np.float64(0.5), 6: np.float64(0.45000000000000007), 7: np.float64(0.5)}\n"
     ]
    }
   ],
   "source": [
    "# 1) โหลดและเตรียมข้อมูล train/dev อีกครั้ง\n",
    "import pandas as pd, ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# โหลดไฟล์ที่แบ่งไว้\n",
    "train_df = pd.read_csv(\"crime-charges-analysis/train_half.csv\")\n",
    "dev_df   = pd.read_csv(\"crime-charges-analysis/dev_half.csv\")\n",
    "\n",
    "# ฟังก์ชัน parse answers\n",
    "def parse_answers(cell: str) -> dict[str, list[int]]:\n",
    "    raw = ast.literal_eval(cell)\n",
    "    out = {}\n",
    "    for d in raw:\n",
    "        for p, cs in d.items():\n",
    "            out[p] = ast.literal_eval(cs)\n",
    "    return out\n",
    "\n",
    "train_df[\"parsed\"] = train_df[\"answers\"].apply(parse_answers)\n",
    "dev_df  [\"parsed\"] = dev_df  [\"answers\"].apply(parse_answers)\n",
    "\n",
    "# สร้าง X_train, Y_train, X_dev, Y_dev\n",
    "X_train, y_train = [], []\n",
    "for _, row in train_df.iterrows():\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_train.append(f\"{person} [SEP] {row['story']}\")\n",
    "        y_train.append(charges)\n",
    "\n",
    "X_dev, y_dev = [], []\n",
    "for _, row in dev_df.iterrows():\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_dev.append(f\"{person} [SEP] {row['story']}\")\n",
    "        y_dev.append(charges)\n",
    "\n",
    "# แปลง labels → binary matrix\n",
    "mlb = MultiLabelBinarizer(classes=[1,2,3,4,5,6,7])\n",
    "Y_train = mlb.fit_transform(y_train)\n",
    "Y_dev   = mlb.transform(y_dev)\n",
    "\n",
    "# 2) สร้าง ML pipeline (TF-IDF + LogisticRegression)\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=30000)),\n",
    "    (\"clf\", OneVsRestClassifier(\n",
    "        LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\"),\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# 3) คำนวณ best threshold per class บน dev set\n",
    "probs = pipeline.predict_proba(X_dev)  # ค่า probability shape = (n_samples, 7)\n",
    "best_thresh = {}\n",
    "for i, cls in enumerate([1,2,3,4,5,6,7]):\n",
    "    best_f1, best_t = 0, 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 17):\n",
    "        y_t = (probs[:, i] >= t).astype(int)\n",
    "        f1 = f1_score(Y_dev[:, i], y_t)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    best_thresh[cls] = best_t\n",
    "    print(f\"Class {cls}: best threshold = {best_t:.2f} with F1 = {best_f1:.3f}\")\n",
    "\n",
    "print(\"\\nThreshold dictionary:\", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4730a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# คำนวณ best_thresh จาก dev set (รันครั้งเดียว)\n",
    "import numpy as np\n",
    "probs = pipeline.predict_proba(X_dev)  # X_dev = [f\"{person} [SEP] {story}\"…]\n",
    "best_thresh = {}\n",
    "for i, cls in enumerate([1,2,3,4,5,6,7]):\n",
    "    best_f1, best_t = 0, .5\n",
    "    for t in np.linspace(0.1,0.9,17):\n",
    "        y_t = (probs[:,i]>=t).astype(int)\n",
    "        f1 = f1_score(Y_dev[:,i], y_t)\n",
    "        if f1>best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    best_thresh[cls] = best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0922d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: best threshold = 0.40 with F1 = 0.524\n",
      "Class 2: best threshold = 0.50 with F1 = 0.712\n",
      "Class 3: best threshold = 0.45 with F1 = 0.676\n",
      "Class 4: best threshold = 0.55 with F1 = 0.739\n",
      "Class 5: best threshold = 0.50 with F1 = 0.635\n",
      "Class 6: best threshold = 0.45 with F1 = 0.677\n",
      "Class 7: best threshold = 0.50 with F1 = 0.706\n",
      "\n",
      "Threshold dictionary: {1: np.float64(0.4), 2: np.float64(0.5), 3: np.float64(0.45000000000000007), 4: np.float64(0.55), 5: np.float64(0.5), 6: np.float64(0.45000000000000007), 7: np.float64(0.5)}\n"
     ]
    }
   ],
   "source": [
    "# 1) โหลดและเตรียมข้อมูล train/dev อีกครั้ง\n",
    "import pandas as pd, ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# โหลดไฟล์ที่แบ่งไว้\n",
    "train_df = pd.read_csv(\"crime-charges-analysis/train_half.csv\")\n",
    "dev_df   = pd.read_csv(\"crime-charges-analysis/dev_half.csv\")\n",
    "\n",
    "# ฟังก์ชัน parse answers\n",
    "def parse_answers(cell: str) -> dict[str, list[int]]:\n",
    "    raw = ast.literal_eval(cell)\n",
    "    out = {}\n",
    "    for d in raw:\n",
    "        for p, cs in d.items():\n",
    "            out[p] = ast.literal_eval(cs)\n",
    "    return out\n",
    "\n",
    "train_df[\"parsed\"] = train_df[\"answers\"].apply(parse_answers)\n",
    "dev_df  [\"parsed\"] = dev_df  [\"answers\"].apply(parse_answers)\n",
    "\n",
    "# สร้าง X_train, Y_train, X_dev, Y_dev\n",
    "X_train, y_train = [], []\n",
    "for _, row in train_df.iterrows():\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_train.append(f\"{person} [SEP] {row['story']}\")\n",
    "        y_train.append(charges)\n",
    "\n",
    "X_dev, y_dev = [], []\n",
    "for _, row in dev_df.iterrows():\n",
    "    for person, charges in row[\"parsed\"].items():\n",
    "        X_dev.append(f\"{person} [SEP] {row['story']}\")\n",
    "        y_dev.append(charges)\n",
    "\n",
    "# แปลง labels → binary matrix\n",
    "mlb = MultiLabelBinarizer(classes=[1,2,3,4,5,6,7])\n",
    "Y_train = mlb.fit_transform(y_train)\n",
    "Y_dev   = mlb.transform(y_dev)\n",
    "\n",
    "# 2) สร้าง ML pipeline (TF-IDF + LogisticRegression)\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=30000)),\n",
    "    (\"clf\", OneVsRestClassifier(\n",
    "        LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\"),\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# 3) คำนวณ best threshold per class บน dev set\n",
    "probs = pipeline.predict_proba(X_dev)  # ค่า probability shape = (n_samples, 7)\n",
    "best_thresh = {}\n",
    "for i, cls in enumerate([1,2,3,4,5,6,7]):\n",
    "    best_f1, best_t = 0, 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 17):\n",
    "        y_t = (probs[:, i] >= t).astype(int)\n",
    "        f1 = f1_score(Y_dev[:, i], y_t)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    best_thresh[cls] = best_t\n",
    "    print(f\"Class {cls}: best threshold = {best_t:.2f} with F1 = {best_f1:.3f}\")\n",
    "\n",
    "print(\"\\nThreshold dictionary:\", best_thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
